#comentario para revivirlo
name: Descargar archivos ENARGAS

on:
  schedule:
    - cron: '0 9 * * *'  # Todos los dÃ­as a las 6 AM Argentina
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout del repositorio
      uses: actions/checkout@v4

    - name: Instalar dependencias Python
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Instalar Chrome (rÃ¡pido)
      uses: browser-actions/setup-chrome@v1
# scraper descarga los xls de la pagina del enargas
    - name: Ejecutar el scraper
      run: |
        python scraper_enargas.py

   # - name: Subir archivos al repo
   #   run: |
   #     git config --global user.name "github-actions"
   #     git config --global user.email "actions@github.com"
   #     git add descargas_enargas/*.xls || echo "Nada para agregar"
   #     git commit -m "ðŸ“Š Archivos descargados automÃ¡ticamente" || echo "Nada para commitear"
   #     git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
   #     git push origin HEAD:main
   
# upload_to_drive sube los xls de la pagina del enargas a un gdrive
    - name: Subir archivos a Google Drive
      env:
        GDRIVE_CREDENTIALS: ${{ secrets.GDRIVE_CREDENTIALS }}
      run: |
        python upload_to_drive.py

# procesar_a_db carga los valores de los excel en la DB de supabase
    - name: Cargar datos en Supabase
      env:
     #   DATABASE_URL: ${{ secrets.DATABASE_URL }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

      run: |
         python -u procesar_a_db.py

# Entre solo mantenerlo vivo
    


        
